import time
from itertools import count

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split, KFold
from imblearn.over_sampling import SMOTE
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier

data = pd.read_csv("dataset/dataset.csv")
data = data.drop(columns='appeared')
data = data.drop('sha256', axis=1)
features = data.drop(columns='label').values
labels = data['label'].values

kf = KFold(n_splits=10, shuffle=False)
max = 0
train_features, train_labels, test_features, test_labels = [], [], [], []
for training_index, testing_index in kf.split(features):
    #print("TRAIN:", training_index, "TEST:", testing_index)
    x_train, x_test = features[training_index], features[testing_index]
    y_train, y_test = labels[training_index], labels[testing_index]
    model = SVC(kernel="linear")
    model.fit(x_train, y_train)
    score = model.score(x_test, y_test)
    if score > max:
        max = score
        train_features = x_train
        train_labels = y_train
        test_features = x_test
        test_labels = y_test

#Data Balancing
sm = SMOTE()
train_features_bal, train_labels_bal = sm.fit_resample(train_features, train_labels)

#Classification SVC
svmstruct = SVC(kernel="linear")
start_time = time.time()
svmstruct.fit(train_features, train_labels)
y_predict = svmstruct.predict(test_features)
cm = confusion_matrix(test_labels, y_predict)
print(cm)
print(classification_report(test_labels, y_predict))
