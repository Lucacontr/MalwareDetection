import time

import pandas as pd
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.metrics import  classification_report, ConfusionMatrixDisplay
from sklearn.model_selection import KFold
from imblearn.over_sampling import SMOTE
from sklearn.svm import SVC
import matplotlib.pyplot as plt
import numpy as np

data = pd.read_csv("dataset/Small&Balanced.csv")
data = data.drop('hash', axis=1)
features = data.drop(columns='malware').values
labels = data['malware'].values

#Data Exploration

labels_ = np.unique(labels)
occurrences = {}
for i in labels.data:
    if i in occurrences:
        occurrences[i] += 1
    else:
        occurrences[i] = 1
sizes = occurrences.values()

fig1, ax1 = plt.subplots()
ax1.pie(sizes, labels=[1, 0], autopct='%1.1f%%')
ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title("Labels distribution Before Validation")
plt.show()


#Validation
kf = KFold(n_splits=10, shuffle=True)
max = 0
train_features, train_labels, test_features, test_labels = [], [], [], []
for training_index, testing_index in kf.split(features):
    x_train, x_test = features[training_index], features[testing_index]
    y_train, y_test = labels[training_index], labels[testing_index]
    model = SVC(kernel="linear")
    model.fit(x_train, y_train)
    score = model.score(x_test, y_test)
    print("Max: ", max, "Actual: ", score)
    if score > max:
        max = score
        train_features = x_train
        train_labels = y_train
        test_features = x_test
        test_labels = y_test

print("Feature Selection..")
#Feature Selection
kbest = SelectKBest(score_func=chi2, k=750)
train_features = kbest.fit_transform(train_features, train_labels)
test_features = kbest.transform(test_features)

print("Feature Extraction..")
# Feature Extraction
pca = PCA(250)
pca.fit(train_features)
train_features = pca.transform(train_features)
test_features = pca.transform(test_features)


labels_ = np.unique(train_labels)
occurrences = {}
for i in train_labels.data:
    if i in occurrences:
        occurrences[i] += 1
    else:
        occurrences[i] = 1
sizes = occurrences.values()
fig1, ax1 = plt.subplots()
ax1.pie(sizes, labels=[1, 0], autopct='%1.1f%%')
ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title("Labels distribution before Data Balancing")

print("Data Balancing..")
#Data Balancing
sm = SMOTE()
train_features, train_labels = sm.fit_resample(train_features, train_labels)


labels_ = np.unique(train_labels)
occurrences = {}
for i in train_labels.data:
    if i in occurrences:
        occurrences[i] += 1
    else:
        occurrences[i] = 1
sizes = occurrences.values()
fig1, ax1 = plt.subplots()
ax1.pie(sizes, labels=[1, 0], autopct='%1.1f%%')
ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title("Train Labels distribution Balanced")
plt.show()

print("Number of test 1: ", np.count_nonzero(test_labels == 1))
print("Number of test 0: ", np.count_nonzero(test_labels == 0))

#Classification SVC
model = SVC(kernel="linear")
start_time = time.time()
model.fit(train_features, train_labels)
y_predict = model.predict(test_features)
total_time = time.time() - start_time
print("Train effettuato in " + str(total_time))
print("\n\n\nLinear SVC")
print(classification_report(test_labels, y_predict))
disp = ConfusionMatrixDisplay.from_estimator(
    model,
    test_features,
    test_labels,
    display_labels=[0, 1],
    cmap=plt.cm.Blues
)
disp.ax_.set_title("Linear SVC Confusion Matrix")
print(disp.confusion_matrix)
plt.show()

